{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6f2f9d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"./COGS/train.tsv\", sep=\"\\t\", names=['sentence', 'LF', 'type'])\n",
    "dev_df = pd.read_csv(\"./COGS/dev.tsv\", sep=\"\\t\", names=['sentence', 'LF', 'type'])\n",
    "dev_tiny_df = pd.read_csv(\"./COGS/dev_tiny.tsv\", sep=\"\\t\", names=['sentence', 'LF', 'type'])\n",
    "test_df = pd.read_csv(\"./COGS/test.tsv\", sep=\"\\t\", names=['sentence', 'LF', 'type'])\n",
    "gen_df = pd.read_csv(\"./COGS/gen.tsv\", sep=\"\\t\", names=['sentence', 'LF', 'type'])\n",
    "gen_lexical_df = pd.read_csv(\"./COGS/gen_lexical.tsv\", sep=\"\\t\", names=['sentence', 'LF', 'type'])\n",
    "gen_structural_df = pd.read_csv(\"./COGS/gen_structural.tsv\", sep=\"\\t\", names=['sentence', 'LF', 'type'])\n",
    "train_df_original = pd.read_csv(\"./COGS/train.tsv\", sep=\"\\t\", names=['sentence', 'LF', 'type'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "774b0419",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.second_looks_utils import *\n",
    "from utils.train_utils import *\n",
    "import spacy\n",
    "import json\n",
    "\n",
    "existing_digit_pool = set([])\n",
    "# loading target vocab to random sample our variable names\n",
    "for k, v in load_vocab(\"./data/tgt_vocab.txt\").items():\n",
    "    if k.isnumeric():\n",
    "        existing_digit_pool.add(k)\n",
    "existing_digit_pool = list(existing_digit_pool)\n",
    "\n",
    "def translate(text, phi):\n",
    "    \n",
    "    if len(phi.split()) == 1:\n",
    "        return text, f\"LAMBDA a . {phi} ( a )\"\n",
    "    elif \"LAMBDA\" in phi:\n",
    "        if len(phi.split()) == 7:\n",
    "            return text, phi\n",
    "        phi_split = phi.split(text)\n",
    "        cleaned_phi = []\n",
    "        for chunk in phi_split:\n",
    "            if \"LAMBDA\" in chunk:\n",
    "                cleaned_phi += [chunk.strip()]\n",
    "            else:\n",
    "                verb_args = chunk.strip(\" .\").split()[2]\n",
    "                cleaned_phi += [chunk.strip(\" .\")]\n",
    "        return text, \" \".join(cleaned_phi[:1] + [f\"{text} ( {verb_args} ) AND\"] + cleaned_phi[1:])\n",
    "    \n",
    "    # parse\n",
    "    text_split = text.split()\n",
    "    data = []    \n",
    "    conjs = re.split(r\"\\s*(?:AND|;)\\s*\", phi)\n",
    "    for conj in conjs: \n",
    "        if np_re.search(conj):\n",
    "            d = parse_np(conj)\n",
    "        elif pred_re.search(conj):\n",
    "            d = parse_pred(conj)\n",
    "            if \"x _\" not in d['entvar']:\n",
    "                d['entvar_name'] = d['entvar']\n",
    "                assert text_split.count(d['entvar']) == 1\n",
    "                name_idx = text_split.index(d['entvar'])\n",
    "                d['entvar'] = f\"x _ {name_idx}\"\n",
    "        elif mod_re.search(conj):\n",
    "            d = parse_mod(conj)\n",
    "        else:\n",
    "            raise Exception(f\"Conjunct could not be parsed: {conj}\")\n",
    "        data.append(d)\n",
    "    \n",
    "    # collect\n",
    "    def_terms = []\n",
    "    role_terms = []\n",
    "    for d in data:\n",
    "        if d['type'] == 'np':\n",
    "            if d['definiteness'] == '*':\n",
    "                def_terms += [f\"* {d['pred']} ( {d['entvar']} )\"]\n",
    "            else:\n",
    "                def_terms += [f\"{d['pred']} ( {d['entvar']} )\"]\n",
    "        if d['type'] == 'role':\n",
    "            if f\"{d['pred']} ( {d['eventvar']} )\" not in role_terms:\n",
    "                role_terms += [f\"{d['pred']} ( {d['eventvar']} )\"]\n",
    "            role_terms += [f\"{d['role']} ( {d['eventvar']} , {d['entvar']} )\"]\n",
    "            if \"entvar_name\" in d:\n",
    "                def_terms += [f\"{d['entvar_name']} ( {d['entvar']} )\"]\n",
    "        elif d['type'] == 'mod':\n",
    "            role_terms += [f\"nmod . {d['pred']} ( {d['e1']} , {d['e2']} )\"]\n",
    "            \n",
    "    # sort def_terms\n",
    "    def_terms = [*set(def_terms)]\n",
    "    def_terms.sort(key = lambda x: int(x.split()[-2]))\n",
    "\n",
    "    rest_terms = role_terms\n",
    "    \n",
    "    # combine\n",
    "    def_terms = \" ; \".join(def_terms)\n",
    "    if def_terms == \"\":\n",
    "        terms = \" AND \".join(rest_terms)\n",
    "    elif \" AND \".join(rest_terms) == \"\":\n",
    "        terms = def_terms\n",
    "    else:\n",
    "        terms = def_terms + \" ; \" + \" AND \".join(rest_terms)\n",
    "    \n",
    "    # final step, remove biases\n",
    "    current_digit_pool = set([])\n",
    "    for t in terms.split():\n",
    "        if t.isnumeric():\n",
    "            current_digit_pool.add(t)\n",
    "    current_digit_pool = list(current_digit_pool)\n",
    "    random.shuffle(current_digit_pool)\n",
    "    sample_random_digit = random.sample(existing_digit_pool, k=len(current_digit_pool))\n",
    "    digit_mapping = dict(zip(current_digit_pool, sample_random_digit))\n",
    "\n",
    "    new_terms = []\n",
    "    for t in terms.split():\n",
    "        if t == \"_\" or t == \"x\":\n",
    "            continue\n",
    "        if t.isnumeric():\n",
    "            new_terms += [digit_mapping[t]]\n",
    "        else:\n",
    "            new_terms += [t]\n",
    "\n",
    "    terms = \" \".join(new_terms)\n",
    "    return text, terms\n",
    "\n",
    "sampled_n = 5\n",
    "append_k = 3072\n",
    "\n",
    "train_dfs = []\n",
    "for i in range(sampled_n):\n",
    "    train_df_i = train_df.copy()\n",
    "    train_df_i[['sentence', 'LF']] = train_df_i[['sentence', 'LF']].apply(lambda x: translate(*x), axis=1, result_type='expand')\n",
    "    train_dfs += [train_df_i]\n",
    "\n",
    "train_df_original[['sentence', 'LF']] = train_df_original[['sentence', 'LF']].apply(lambda x: translate(*x), axis=1, result_type='expand')\n",
    "dev_df[['sentence', 'LF']] = dev_df[['sentence', 'LF']].apply(lambda x: translate(*x), axis=1, result_type='expand')\n",
    "test_df[['sentence', 'LF']] = test_df[['sentence', 'LF']].apply(lambda x: translate(*x), axis=1, result_type='expand')\n",
    "gen_df[['sentence', 'LF']] = gen_df[['sentence', 'LF']].apply(lambda x: translate(*x), axis=1, result_type='expand')\n",
    "gen_lexical_df[['sentence', 'LF']] = gen_lexical_df[['sentence', 'LF']].apply(lambda x: translate(*x), axis=1, result_type='expand')\n",
    "gen_structural_df[['sentence', 'LF']] = gen_structural_df[['sentence', 'LF']].apply(lambda x: translate(*x), axis=1, result_type='expand')\n",
    "dev_tiny_df[['sentence', 'LF']] = dev_tiny_df[['sentence', 'LF']].apply(lambda x: translate(*x), axis=1, result_type='expand')\n",
    "\n",
    "def reindex(LFs, existing_digit_pool):\n",
    "    curr_digit = set([])\n",
    "    for i in range(len(LFs)):\n",
    "        for item in LFs[i].split():\n",
    "            if item.isnumeric():\n",
    "                curr_digit.add((i, int(item)))\n",
    "    sampled_digits = random.sample(existing_digit_pool, k=len(curr_digit))\n",
    "    digit_map = {}\n",
    "    idx = 0\n",
    "    for d in list(curr_digit):\n",
    "        digit_map[d] = sampled_digits[idx]\n",
    "        idx += 1\n",
    "    \n",
    "    reindex_LFs = []\n",
    "    for i in range(len(LFs)):\n",
    "        new_LFs = []\n",
    "        for item in LFs[i].split():\n",
    "            if item.isnumeric():\n",
    "                new_LFs += [digit_map[(i, int(item))]]\n",
    "            else:\n",
    "                new_LFs += [item]\n",
    "        reindex_LFs += [\" \".join(new_LFs)]\n",
    "        \n",
    "    new_LF_prefix = []\n",
    "    new_LF_body_role = []\n",
    "        \n",
    "    for i in range(len(reindex_LFs)):\n",
    "        new_LF_prefix.extend(reindex_LFs[i].split(\" ; \")[:-1])\n",
    "        for term in reindex_LFs[i].split(\" ; \")[-1].split(\" AND \"):\n",
    "            new_LF_body_role += [term]\n",
    "                \n",
    "    new_LF_body = new_LF_body_role\n",
    "        \n",
    "    return \" ; \".join(new_LF_prefix) + \" ; \" + \" AND \".join(new_LF_body)\n",
    "\n",
    "start_indexes = [i*6 for i in range(append_k)]\n",
    "append_data = []\n",
    "\n",
    "for i in range(sampled_n):\n",
    "    train_df_sorted = train_dfs[i].sort_values(by=\"sentence\", key=lambda x: x.str.len())\n",
    "    for start_index in start_indexes:\n",
    "        conj_1 = train_df_sorted.iloc[-2-start_index].sentence\n",
    "        if conj_1.split()[0] in {'The', 'A'}:\n",
    "            conj_1_first = conj_1[0].lower()\n",
    "        else:\n",
    "            conj_1_first = conj_1[0]\n",
    "            \n",
    "        conj_2 = train_df_sorted.iloc[-3-start_index].sentence\n",
    "        if conj_2.split()[0] in {'The', 'A'}:\n",
    "            conj_2_first = conj_2[0].lower()\n",
    "        else:\n",
    "            conj_2_first = conj_2[0]\n",
    "            \n",
    "        append_data += [\n",
    "            [train_df_sorted.iloc[-1-start_index].sentence[:-1]+\\\n",
    "            conj_1_first+\\\n",
    "            train_df_sorted.iloc[-2-start_index].sentence[1:-1]+\\\n",
    "            conj_2_first+\\\n",
    "            train_df_sorted.iloc[-3-start_index].sentence[1:],\n",
    "            reindex(\n",
    "                [\n",
    "                    train_df_sorted.iloc[-1-start_index].LF,\n",
    "                    train_df_sorted.iloc[-2-start_index].LF,\n",
    "                    train_df_sorted.iloc[-3-start_index].LF\n",
    "                ], existing_digit_pool\n",
    "            ),\n",
    "            'length_ood']\n",
    "        ]\n",
    "append_data = pd.DataFrame(append_data, columns =['sentence', 'LF', 'type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3c05a25a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.concat(train_dfs)\n",
    "train_df = pd.concat([train_df, append_data])\n",
    "train_df = train_df.drop_duplicates()\n",
    "\n",
    "dataset_postfix = \"COGS\"\n",
    "train_df_original.to_csv(f'./{dataset_postfix}/RECOGStrain.tsv', sep='\\t', index=False, header=False)\n",
    "dev_df.to_csv(f'./{dataset_postfix}/RECOGSdev.tsv', sep='\\t', index=False, header=False)\n",
    "test_df.to_csv(f'./{dataset_postfix}/RECOGStest.tsv', sep='\\t', index=False, header=False)\n",
    "gen_df.to_csv(f'./{dataset_postfix}/RECOGSgen.tsv', sep='\\t', index=False, header=False)\n",
    "gen_lexical_df.to_csv(f'./{dataset_postfix}/RECOGSgen_lexical.tsv', sep='\\t', index=False, header=False)\n",
    "gen_structural_df.to_csv(f'./{dataset_postfix}/RECOGSgen_structural.tsv', sep='\\t', index=False, header=False)\n",
    "dev_tiny_df.to_csv(f'./{dataset_postfix}/RECOGSdev_tiny.tsv', sep='\\t', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ab177ea0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>LF</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Liam hoped that a box was burned by a girl .</td>\n",
       "      <td>Liam ( 30 ) ; box ( 29 ) ; girl ( 17 ) ; hope ...</td>\n",
       "      <td>in_distribution</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The donkey lended the cookie to a mother .</td>\n",
       "      <td>* donkey ( 3 ) ; * cookie ( 26 ) ; mother ( 59...</td>\n",
       "      <td>in_distribution</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A melon was given to a girl by the guard .</td>\n",
       "      <td>melon ( 30 ) ; girl ( 40 ) ; * guard ( 59 ) ; ...</td>\n",
       "      <td>in_distribution</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A donut was given to a butterfly .</td>\n",
       "      <td>donut ( 0 ) ; butterfly ( 25 ) ; give ( 11 ) A...</td>\n",
       "      <td>in_distribution</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A rose was mailed to Isabella .</td>\n",
       "      <td>rose ( 15 ) ; Isabella ( 32 ) ; mail ( 16 ) AN...</td>\n",
       "      <td>in_distribution</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2995</th>\n",
       "      <td>A frog supported that the box was appreciated .</td>\n",
       "      <td>frog ( 59 ) ; * box ( 38 ) ; support ( 25 ) AN...</td>\n",
       "      <td>in_distribution</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2996</th>\n",
       "      <td>Ava gave the cake to Emma .</td>\n",
       "      <td>Ava ( 24 ) ; * cake ( 1 ) ; Emma ( 3 ) ; give ...</td>\n",
       "      <td>in_distribution</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2997</th>\n",
       "      <td>Benjamin intended to clean .</td>\n",
       "      <td>Benjamin ( 16 ) ; intend ( 23 ) AND agent ( 23...</td>\n",
       "      <td>in_distribution</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2998</th>\n",
       "      <td>Ethan rolled a ring .</td>\n",
       "      <td>Ethan ( 38 ) ; ring ( 52 ) ; roll ( 27 ) AND a...</td>\n",
       "      <td>in_distribution</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999</th>\n",
       "      <td>Matthew handed a bird the cookie beside the ta...</td>\n",
       "      <td>Matthew ( 4 ) ; bird ( 8 ) ; * cookie ( 28 ) ;...</td>\n",
       "      <td>in_distribution</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               sentence  \\\n",
       "0          Liam hoped that a box was burned by a girl .   \n",
       "1            The donkey lended the cookie to a mother .   \n",
       "2            A melon was given to a girl by the guard .   \n",
       "3                    A donut was given to a butterfly .   \n",
       "4                       A rose was mailed to Isabella .   \n",
       "...                                                 ...   \n",
       "2995    A frog supported that the box was appreciated .   \n",
       "2996                        Ava gave the cake to Emma .   \n",
       "2997                       Benjamin intended to clean .   \n",
       "2998                              Ethan rolled a ring .   \n",
       "2999  Matthew handed a bird the cookie beside the ta...   \n",
       "\n",
       "                                                     LF             type  \n",
       "0     Liam ( 30 ) ; box ( 29 ) ; girl ( 17 ) ; hope ...  in_distribution  \n",
       "1     * donkey ( 3 ) ; * cookie ( 26 ) ; mother ( 59...  in_distribution  \n",
       "2     melon ( 30 ) ; girl ( 40 ) ; * guard ( 59 ) ; ...  in_distribution  \n",
       "3     donut ( 0 ) ; butterfly ( 25 ) ; give ( 11 ) A...  in_distribution  \n",
       "4     rose ( 15 ) ; Isabella ( 32 ) ; mail ( 16 ) AN...  in_distribution  \n",
       "...                                                 ...              ...  \n",
       "2995  frog ( 59 ) ; * box ( 38 ) ; support ( 25 ) AN...  in_distribution  \n",
       "2996  Ava ( 24 ) ; * cake ( 1 ) ; Emma ( 3 ) ; give ...  in_distribution  \n",
       "2997  Benjamin ( 16 ) ; intend ( 23 ) AND agent ( 23...  in_distribution  \n",
       "2998  Ethan ( 38 ) ; ring ( 52 ) ; roll ( 27 ) AND a...  in_distribution  \n",
       "2999  Matthew ( 4 ) ; bird ( 8 ) ; * cookie ( 28 ) ;...  in_distribution  \n",
       "\n",
       "[3000 rows x 3 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_df\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bade5b81",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
